# Trino on ECS 기반 DataLake 플랫폼

## 프로젝트 개요

데이터 레이크가 부재하고 S3를 단순히 Redshift 로드를 위한 임시 공간으로만 활용하던 환경에서,
**데이터 활용성을 극대화하고 통합적인 분석 기반을 마련하기 위해 Trino 기반의 데이터 레이크 플랫폼을 구축**했습니다.


EKS와 같은 관리형 쿠버네티스 서비스 없이 **ECS를 활용하여 Trino를 직접 배포하고 운영**함으로써, 분산된 데이터 소스를 효율적으로 통합하고 데이터 접근성을 혁신적으로 개선했습니다.

### 아키텍처
- ECS(Trino) <-> S3, RDB, Redshift, Google Sheet
![아키텍처](/static/images/projects/trino-ecs-platform/architecture.png)

---

## 프로젝트 목표

1.  **초기 데이터 레이크 플랫폼 구축**: S3를 중심으로 한 데이터 레이크의 기틀을 마련하고, 데이터의 저장, 관리, 활용을 위한 통합된 환경을 제공합니다.
2.  **Federated Query를 통한 통합 분석 환경 제공**: Redshift, Aurora(MySQL), S3, Spreadsheet 등 다양한 데이터 소스를 단일 쿼리로 접근할 수 있는 통합 쿼리 엔진을 구축하여 데이터 분석의 복잡성을 해소합니다.
3.  **데이터 접근성 및 활용도 증대**: 데이터 분석가들이 원본 데이터를 직접 탐색하고, 비개발 직군의 스프레드시트 분석과 같은 다양한 분석 요구를 충족할 수 있는 환경을 조성합니다.

---

## 기술적 도전과 해결 과정

### 1. EKS 부재 환경에서의 Trino 클러스터 구축
-   **문제**: 관리형 쿠버네티스(EKS) 환경이 없어 팀내 주요 배포 환경인 ECS에 Trino를 직접 배포해야 했습니다. Coordinator와 Worker 간의 네트워킹, 설정 관리, 그리고 탄력적인 확장성 확보가 주요 과제였습니다.
-   **해결**:
    -   **ECS Service Connect**를 도입하여 Coordinator와 Worker 컨테이너 간의 안정적인 통신을 구현했습니다.
    -   **ECS Auto Scaling**을 설정하여 쿼리 부하에 따라 Worker 노드가 자동으로 확장 및 축소되도록 구성하여 비용 효율성을 확보했습니다.
    -   **AWS Parameter Store**를 활용해 Catalog, Connector 등 Trino의 복잡한 설정 정보를 중앙에서 관리하고, 배포 시 동적으로 주입하여 운영 편의성을 높였습니다.
        -   ![catalog_add](/static/images/projects/trino-ecs-platform/catalog_add.png)

### 2. S3 데이터 레이크 비용 관리 전략 수립
-   **문제**: 데이터 레이크의 데이터 양이 증가함에 따라 **S3 스토리지 비용 최적화의 필요성**이 대두되었습니다. 데이터 접근 패턴에 대한 이해 없이 비용을 절감하기는 어려웠습니다.
-   **해결**: 데이터 접근 빈도에 따라 **Hot/Cold 데이터를 구분하는 기준을 수립**하고, **S3 Lifecycle 정책과 Intelligent-Tiering을 적용**하여 사용 빈도가 낮은 데이터는 저렴한 스토리지 클래스로 자동 이동시켰습니다. 이를 통해 실서비스에 영향을 주지 않으면서 **스토리지 비용을 약 40% 절감**했습니다.

### 3. 플랫폼 활용도 증진 및 사용자 교육
-   **문제**: 강력한 쿼리 엔진을 구축했음에도 불구하고, 사용자들이 그 가치를 체감하고 활용하는 데 어려움을 겪었습니다.
-   **해결**:
    -   **사용자 가이드를 작성하고 Trino 소개 세션을 진행**하여 다양한 활용 사례(e.g., Google Sheets 연동)를 전파했습니다.
        -   ![guide](/static/images/projects/trino-ecs-platform/guide.png)
    -   Parameter Store를 통해 **DB 연결 정보를 자동화**하여 사용자가 복잡한 설정 없이도 손쉽게 새로운 데이터 소스를 추가하고 쿼리할 수 있도록 개선했습니다.
    -   `MySQL Query Event Log 설정`을 통해 사용자들의 쿼리 패턴을 분석하고, 이를 바탕으로 플랫폼을 지속적으로 개선했습니다.

---

## 성과 및 임팩트

-   **데이터 분석가 효율성 증대**: 데이터 분석가들이 원본 데이터 확인 및 정합성 확인 시간을 단축 시켜, **핵심 분석 업무에 집중할 수 있는 환경을 마련**했습니다. 또한, Spreadsheet와 연동 같은 기능을 통해 **다양한 데이터 조합의 분석 요구를 충족**시켰습니다.
-   **데이터 웨어하우스(DW) 부하 감소**: 원본 데이터 확인 및 테스트를 위한 쿼리를 Trino로 분산시켜 **Redshift의 리소스 부담을 최소화**하고, 핵심적인 BI 및 리포팅 성능을 안정적으로 유지했습니다.
-   **미래지향적 아키텍처 기반 마련**: 본 프로젝트를 통해 **Iceberg와 같은 Lakehouse 아키텍처로 발전할 수 있는 기술적, 경험적 토대를 마련**했습니다.

---

## 배운 점과 향후 개선 방향

### 배운 점
-   **오픈소스 커스터마이징 및 내재화 역량**: 단순히 Quick-Start 가이드를 따르는 것을 넘어, Trino라는 오픈소스를 팀의 핵심 인프라인 ECS 환경에 맞게 직접 구성하고 최적화하며 **인프라에 대한 깊은 이해와 문제 해결 능력**을 길렀습니다.
-   **데이터 플랫폼의 안정성 및 확장성**: 단일 데이터 파이프라인 구축 경험을 넘어, 무중단 배포, 동적 설정 관리 등 **플랫폼 사용자 전체를 고려하는 안정성과 확장성에 대해 고민**해보는 귀중한 경험이었습니다.
-   **자동화를 통한 운영 효율화**: Parameter Store를 활용한 설정 자동화는 **플랫폼의 유지보수 비용을 절감**하고, 사용자가 더 쉽고 빠르게 가치를 창출할 수 있도록 돕는다는 것을 깨달았습니다.

### 향후 개선 방향
-   **무중단 배포 도입**: 무중단 배포 기능을 구현하여 **카탈로그 추가 및 설정 변경 시에도 서비스 중단 없이 안정적으로 업데이트**할 수 있는 배포 파이프라인을 구축할 계획입니다.
-   **DW와의 통합성 강화**: Trino와 Redshift 간의 데이터 동기화 및 쿼리 최적화를 통해 **데이터 웨어하우스와의 통합성을 더욱 높이고, 실시간 데이터 분석 환경을 구축**할 예정입니다.
