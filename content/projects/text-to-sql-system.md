# LLM ê¸°ë°˜ Text-to-SQL ì‹œìŠ¤í…œ

## í”„ë¡œì íŠ¸ ê°œìš”

LangChainê³¼ OpenAI GPTë¥¼ í™œìš©í•œ ìì—°ì–´ ê¸°ë°˜ SQL ìƒì„± ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ì—¬ ë¹„ê°œë°œìë„ ì‰½ê²Œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì •ë³´ë¥¼ ì¡°íšŒí•  ìˆ˜ ìˆëŠ” í˜ì‹ ì ì¸ ì†”ë£¨ì…˜ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ ë³µì¡í•œ SQL ì¿¼ë¦¬ë¥¼ ìì—°ì–´ë¡œ ë³€í™˜í•˜ì—¬ ë°ì´í„° ì ‘ê·¼ì„±ì„ íšê¸°ì ìœ¼ë¡œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.

**í•µì‹¬ ì„±ê³¼:**
- ë°ì´í„° ì¶”ì¶œ ìš”ì²­ 40% ê°ì†Œë¡œ ì—”ì§€ë‹ˆì–´ ì—…ë¬´ íš¨ìœ¨ì„± ì¦ëŒ€
- ìì—°ì–´ â†’ SQL ë³€í™˜ ì •í™•ë„ 85% ë‹¬ì„±
- ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ë¡œ ì‚¬ìš©ì ë§Œì¡±ë„ 95% ë‹¬ì„±
- í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ìœ¼ë¡œ ë„ë©”ì¸ íŠ¹í™” ì„±ëŠ¥ ìµœì í™”

## í”„ë¡œì íŠ¸ ëª©í‘œ

### ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­
1. **ë°ì´í„° ë¯¼ì£¼í™”**: ë¹„ê°œë°œìì˜ ì…€í”„ ì„œë¹„ìŠ¤ ë°ì´í„° ì ‘ê·¼ í™˜ê²½ êµ¬ì¶•
2. **ì—…ë¬´ íš¨ìœ¨ì„±**: ë°˜ë³µì ì¸ ë°ì´í„° ì¶”ì¶œ ìš”ì²­ ì—…ë¬´ ìë™í™”
3. **ì˜ì‚¬ê²°ì • ì§€ì›**: ì‹¤ì‹œê°„ ë°ì´í„° ì¡°íšŒë¥¼ í†µí•œ ë¹ ë¥¸ ì˜ì‚¬ê²°ì • ì§€ì›
4. **í•™ìŠµ íš¨ê³¼**: SQL í•™ìŠµ ë„êµ¬ë¡œ í™œìš©í•˜ì—¬ ì¡°ì§ ì—­ëŸ‰ ê°•í™”

### ê¸°ìˆ ì  ëª©í‘œ
- LLM ê¸°ë°˜ ìì—°ì–´ ì´í•´ ë° SQL ìƒì„± ì‹œìŠ¤í…œ êµ¬ì¶•
- ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ìë™ ì¸ì‹ ë° ì ì‘í˜• ì¿¼ë¦¬ ìƒì„±
- ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•œ ì§ê´€ì ì¸ ì‚¬ìš©ì ê²½í—˜ ì œê³µ
- í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì„ í†µí•œ ë„ë©”ì¸ íŠ¹í™” ìµœì í™”

## ê¸°ìˆ ì  ë„ì „ê³¼ í•´ê²° ê³¼ì •

### 1. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„

**ë„ì „ ê³¼ì œ:**
- ë³µì¡í•œ ê²Œì„ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆì˜ ì´í•´
- ìì—°ì–´ì˜ ëª¨í˜¸ì„±ê³¼ SQLì˜ ì •í™•ì„± ê°„ ê´´ë¦¬
- ì‹¤ì‹œê°„ ì‘ë‹µì„±ê³¼ ì •í™•ì„±ì˜ ê· í˜•

**í•´ê²° ë°©ì•ˆ:**
```
Text-to-SQL System Architecture
â”œâ”€â”€ Frontend (Chainlit Web Interface)
â”‚   â”œâ”€â”€ ëŒ€í™”í˜• ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
â”‚   â”œâ”€â”€ ì‹¤ì‹œê°„ ì¿¼ë¦¬ ê²°ê³¼ í‘œì‹œ
â”‚   â””â”€â”€ SQL ì½”ë“œ í•˜ì´ë¼ì´íŒ…
â”œâ”€â”€ Backend (FastAPI)
â”‚   â”œâ”€â”€ LangChain ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
â”‚   â”œâ”€â”€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê´€ë¦¬
â”‚   â””â”€â”€ ì¿¼ë¦¬ ê²€ì¦ ë° ì‹¤í–‰
â”œâ”€â”€ LLM Integration
â”‚   â”œâ”€â”€ OpenAI GPT-4 (ì£¼ ëª¨ë¸)
â”‚   â”œâ”€â”€ ìŠ¤í‚¤ë§ˆ ì¸ì‹ ì—ì´ì „íŠ¸
â”‚   â””â”€â”€ SQL ìƒì„± ë° ê²€ì¦ ì—ì´ì „íŠ¸
â””â”€â”€ Database Layer
    â”œâ”€â”€ PostgreSQL (ë©”íƒ€ë°ì´í„°)
    â”œâ”€â”€ Redshift (ë¶„ì„ DB)
    â””â”€â”€ Langfuse (ë¡œê¹… & ë¶„ì„)
```

### 2. LangChain ê¸°ë°˜ SQL ìƒì„± ì‹œìŠ¤í…œ

**í•µì‹¬ ì»´í¬ë„ŒíŠ¸ êµ¬í˜„:**
```python
from langchain.llms import OpenAI
from langchain.agents import create_sql_agent
from langchain.agents.agent_toolkits import SQLDatabaseToolkit
from langchain.sql_database import SQLDatabase
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
import os

class GameDataSQLAgent:
    """ê²Œì„ ë°ì´í„° íŠ¹í™” Text-to-SQL ì—ì´ì „íŠ¸"""
    
    def __init__(self, database_url: str, openai_api_key: str):
        self.database_url = database_url
        self.db = SQLDatabase.from_uri(database_url)
        
        # OpenAI LLM ì´ˆê¸°í™”
        self.llm = OpenAI(
            openai_api_key=openai_api_key,
            model_name="gpt-4",
            temperature=0.1,  # ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ì€ temperature
            max_tokens=2000
        )
        
        # SQL íˆ´í‚· ìƒì„±
        self.toolkit = SQLDatabaseToolkit(db=self.db, llm=self.llm)
        
        # ê²Œì„ ë„ë©”ì¸ íŠ¹í™” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self.game_domain_prompt = self.create_game_domain_prompt()
        
        # SQL ì—ì´ì „íŠ¸ ìƒì„±
        self.agent = create_sql_agent(
            llm=self.llm,
            toolkit=self.toolkit,
            verbose=True,
            prompt=self.game_domain_prompt,
            max_iterations=5,
            early_stopping_method="generate"
        )
    
    def create_game_domain_prompt(self):
        """ê²Œì„ ë„ë©”ì¸ íŠ¹í™” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿"""
        
        template = """
ë‹¹ì‹ ì€ ê²Œì„ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆë¬¸ì„ ì •í™•í•œ SQL ì¿¼ë¦¬ë¡œ ë³€í™˜í•˜ì„¸ìš”.

ê²Œì„ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ë³´:
- users: ì‚¬ìš©ì ì •ë³´ (user_id, username, registration_date, country, level)
- game_sessions: ê²Œì„ ì„¸ì…˜ (session_id, user_id, start_time, end_time, game_mode)
- transactions: êµ¬ë§¤ ë‚´ì—­ (transaction_id, user_id, item_id, amount, currency, purchase_date)
- user_events: ì‚¬ìš©ì ì´ë²¤íŠ¸ (event_id, user_id, event_type, event_time, properties)
- items: ê²Œì„ ì•„ì´í…œ (item_id, item_name, item_type, price, rarity)

ì¤‘ìš”í•œ ê·œì¹™:
1. ë‚ ì§œ ì¡°ê±´ì´ ëª…ì‹œë˜ì§€ ì•Šìœ¼ë©´ ìµœê·¼ 30ì¼ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ì„¸ìš”
2. ì‚¬ìš©ì ìˆ˜ë¥¼ ì…€ ë•ŒëŠ” DISTINCTë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
3. ë§¤ì¶œ ê´€ë ¨ ì§ˆë¬¸ì—ëŠ” currency='USD'ì¸ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
4. ê²Œì„ ì„¸ì…˜ ì‹œê°„ì€ (end_time - start_time)ìœ¼ë¡œ ê³„ì‚°í•˜ì„¸ìš”
5. ê²°ê³¼ëŠ” ìµœëŒ€ 1000í–‰ìœ¼ë¡œ ì œí•œí•˜ì„¸ìš”

ì§ˆë¬¸: {question}

SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ê¸° ì „ì— ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:
1. ì–´ë–¤ í…Œì´ë¸”ë“¤ì´ í•„ìš”í•œê°€?
2. ì–´ë–¤ ì¡°ê±´ë“¤ì´ í•„ìš”í•œê°€?
3. ì–´ë–¤ ì§‘ê³„ í•¨ìˆ˜ê°€ í•„ìš”í•œê°€?
4. ì •ë ¬ì´ë‚˜ ì œí•œì´ í•„ìš”í•œê°€?

SQL:
```sql
"""
        
        return PromptTemplate(
            template=template,
            input_variables=["question"]
        )
    
    def generate_sql(self, question: str):
        """ìì—°ì–´ ì§ˆë¬¸ì„ SQLë¡œ ë³€í™˜"""
        
        try:
            # ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¶”ê°€
            schema_info = self.get_schema_info()
            enhanced_question = f"""
ìŠ¤í‚¤ë§ˆ ì •ë³´:
{schema_info}

ì‚¬ìš©ì ì§ˆë¬¸: {question}
"""
            
            # SQL ìƒì„±
            result = self.agent.run(enhanced_question)
            
            # ê²°ê³¼ íŒŒì‹± ë° ê²€ì¦
            sql_query = self.extract_sql_from_result(result)
            validated_sql = self.validate_sql(sql_query)
            
            return {
                'sql': validated_sql,
                'explanation': self.generate_explanation(validated_sql),
                'estimated_rows': self.estimate_result_size(validated_sql)
            }
            
        except Exception as e:
            return {
                'error': f"SQL ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                'suggestion': self.get_error_suggestion(question)
            }
    
    def get_schema_info(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¡°íšŒ"""
        
        schema_query = """
        SELECT 
            table_name,
            column_name,
            data_type,
            is_nullable
        FROM information_schema.columns 
        WHERE table_schema = 'public'
        ORDER BY table_name, ordinal_position
        """
        
        schema_result = self.db.run(schema_query)
        return self.format_schema_info(schema_result)
    
    def validate_sql(self, sql_query: str):
        """ìƒì„±ëœ SQL ì¿¼ë¦¬ ê²€ì¦ ë° ë³´ì•ˆ ê²€ì‚¬"""
        
        # ìœ„í—˜í•œ í‚¤ì›Œë“œ ê²€ì‚¬
        dangerous_keywords = [
            'DROP', 'DELETE', 'UPDATE', 'INSERT', 
            'CREATE', 'ALTER', 'TRUNCATE', 'GRANT', 'REVOKE'
        ]
        
        upper_sql = sql_query.upper()
        for keyword in dangerous_keywords:
            if keyword in upper_sql:
                raise ValueError(f"ë³´ì•ˆìƒ ìœ„í—˜í•œ í‚¤ì›Œë“œ ê°ì§€: {keyword}")
        
        # LIMIT ì ˆ ê°•ì œ ì¶”ê°€
        if 'LIMIT' not in upper_sql:
            sql_query += ' LIMIT 1000'
        
        return sql_query
    
    def execute_sql_safely(self, sql_query: str):
        """ì•ˆì „í•œ SQL ì‹¤í–‰"""
        
        try:
            # ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„ ì œí•œ (30ì´ˆ)
            import signal
            
            def timeout_handler(signum, frame):
                raise TimeoutError("ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼")
            
            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(30)
            
            # SQL ì‹¤í–‰
            result = self.db.run(sql_query)
            
            signal.alarm(0)  # íƒ€ì´ë¨¸ í•´ì œ
            
            return {
                'success': True,
                'data': result,
                'row_count': len(result) if isinstance(result, list) else 1
            }
            
        except TimeoutError:
            return {
                'success': False,
                'error': 'ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì¡°ê±´ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.'
            }
        except Exception as e:
            return {
                'success': False,
                'error': f'ì¿¼ë¦¬ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}'
            }

class ConversationManager:
    """ëŒ€í™”í˜• ì„¸ì…˜ ê´€ë¦¬"""
    
    def __init__(self, sql_agent: GameDataSQLAgent):
        self.sql_agent = sql_agent
        self.conversation_history = []
        self.context_memory = {}
    
    def process_message(self, user_message: str, session_id: str):
        """ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬ ë° ì‘ë‹µ ìƒì„±"""
        
        # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
        enhanced_message = self.add_context(user_message, session_id)
        
        # SQL ìƒì„±
        sql_result = self.sql_agent.generate_sql(enhanced_message)
        
        if 'error' in sql_result:
            response = self.handle_error_response(sql_result, user_message)
        else:
            # SQL ì‹¤í–‰
            execution_result = self.sql_agent.execute_sql_safely(sql_result['sql'])
            response = self.format_success_response(sql_result, execution_result)
        
        # ëŒ€í™” ê¸°ë¡ ì €ì¥
        self.save_conversation(session_id, user_message, response)
        
        return response
    
    def add_context(self, message: str, session_id: str):
        """ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ í˜„ì¬ ë©”ì‹œì§€ì— ì¶”ê°€"""
        
        recent_context = self.get_recent_context(session_id, limit=3)
        
        if recent_context:
            context_str = "\n".join([
                f"ì´ì „ ì§ˆë¬¸: {ctx['question']}"
                for ctx in recent_context
            ])
            
            enhanced_message = f"""
ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸:
{context_str}

í˜„ì¬ ì§ˆë¬¸: {message}
"""
            return enhanced_message
        
        return message
    
    def format_success_response(self, sql_result, execution_result):
        """ì„±ê³µì ì¸ ì‘ë‹µ í¬ë§·íŒ…"""
        
        if execution_result['success']:
            response = {
                'type': 'success',
                'sql': sql_result['sql'],
                'explanation': sql_result['explanation'],
                'data': execution_result['data'],
                'row_count': execution_result['row_count'],
                'suggestions': self.generate_follow_up_suggestions(sql_result['sql'])
            }
        else:
            response = {
                'type': 'execution_error',
                'sql': sql_result['sql'],
                'error': execution_result['error'],
                'suggestions': ['ë” êµ¬ì²´ì ì¸ ì¡°ê±´ì„ ì¶”ê°€í•´ë³´ì„¸ìš”', 'ë‚ ì§œ ë²”ìœ„ë¥¼ ì¤„ì—¬ë³´ì„¸ìš”']
            }
        
        return response
```

### 3. Chainlit ê¸°ë°˜ ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤

**ì‚¬ìš©ì ì¹œí™”ì  ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„:**
```python
import chainlit as cl
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go

@cl.on_chat_start
async def start():
    """ì±„íŒ… ì„¸ì…˜ ì‹œì‘ì‹œ ì´ˆê¸°í™”"""
    
    # SQL ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
    sql_agent = GameDataSQLAgent(
        database_url=os.getenv("DATABASE_URL"),
        openai_api_key=os.getenv("OPENAI_API_KEY")
    )
    
    conversation_manager = ConversationManager(sql_agent)
    
    # ì„¸ì…˜ì— ì €ì¥
    cl.user_session.set("conversation_manager", conversation_manager)
    
    # í™˜ì˜ ë©”ì‹œì§€
    welcome_message = """
ğŸ® **ê²Œì„ ë°ì´í„° ë¶„ì„ AI ì–´ì‹œìŠ¤í„´íŠ¸**ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!

ì €ëŠ” ìì—°ì–´ë¡œ ì§ˆë¬¸í•˜ì‹œë©´ SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ê³  ì‹¤í–‰í•´ë“œë¦¬ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

**ì˜ˆì‹œ ì§ˆë¬¸ë“¤:**
- "ìµœê·¼ 7ì¼ê°„ ì¼ë³„ ì‹ ê·œ ì‚¬ìš©ì ìˆ˜ëŠ”?"
- "ê°€ì¥ ì¸ê¸° ìˆëŠ” ì•„ì´í…œ top 10ì€?"
- "êµ­ê°€ë³„ í‰ê·  ì„¸ì…˜ ì‹œê°„ì„ ì•Œë ¤ì¤˜"
- "ì§€ë‚œ ë‹¬ ë§¤ì¶œì´ ê°€ì¥ ë†’ì€ ì‚¬ìš©ìëŠ”?"

ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”! ğŸš€
"""
    
    await cl.Message(content=welcome_message).send()

@cl.on_message
async def main(message: cl.Message):
    """ë©”ì‹œì§€ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜"""
    
    conversation_manager = cl.user_session.get("conversation_manager")
    
    # ë¡œë”© ë©”ì‹œì§€ í‘œì‹œ
    loading_msg = cl.Message(content="ğŸ¤” ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  SQLì„ ìƒì„±í•˜ëŠ” ì¤‘...")
    await loading_msg.send()
    
    try:
        # ë©”ì‹œì§€ ì²˜ë¦¬
        response = conversation_manager.process_message(
            message.content, 
            cl.user_session.get("id")
        )
        
        # ë¡œë”© ë©”ì‹œì§€ ì œê±°
        await loading_msg.remove()
        
        if response['type'] == 'success':
            await handle_success_response(response)
        else:
            await handle_error_response(response)
            
    except Exception as e:
        await loading_msg.remove()
        await cl.Message(
            content=f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        ).send()

async def handle_success_response(response):
    """ì„±ê³µ ì‘ë‹µ ì²˜ë¦¬"""
    
    # SQL ì½”ë“œ í‘œì‹œ
    sql_element = cl.Code(
        name="ìƒì„±ëœ SQL",
        content=response['sql'],
        language="sql"
    )
    
    # ì„¤ëª… ë©”ì‹œì§€
    explanation_msg = f"""
âœ… **ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ!**

**ì„¤ëª…:** {response['explanation']}

**ê²°ê³¼:** {response['row_count']}ê°œ í–‰ ì¡°íšŒë¨
"""
    
    await cl.Message(
        content=explanation_msg,
        elements=[sql_element]
    ).send()
    
    # ë°ì´í„° í…Œì´ë¸” í‘œì‹œ
    if response['data']:
        df = pd.DataFrame(response['data'])
        
        # ë°ì´í„° í…Œì´ë¸”
        table_element = cl.DataFrame(
            name="ì¿¼ë¦¬ ê²°ê³¼",
            content=df.head(50),  # ìµœëŒ€ 50í–‰ í‘œì‹œ
            display="inline"
        )
        
        await cl.Message(
            content="ğŸ“Š **ì¿¼ë¦¬ ê²°ê³¼:**",
            elements=[table_element]
        ).send()
        
        # ë°ì´í„° ì‹œê°í™” (ì ì ˆí•œ ê²½ìš°)
        chart = await create_chart_if_applicable(df)
        if chart:
            await cl.Message(
                content="ğŸ“ˆ **ë°ì´í„° ì‹œê°í™”:**",
                elements=[chart]
            ).send()
    
    # í›„ì† ì§ˆë¬¸ ì œì•ˆ
    suggestions = response.get('suggestions', [])
    if suggestions:
        suggestion_text = "ğŸ’¡ **ê´€ë ¨ ì§ˆë¬¸ ì œì•ˆ:**\n" + "\n".join([
            f"â€¢ {suggestion}" for suggestion in suggestions
        ])
        
        await cl.Message(content=suggestion_text).send()

async def create_chart_if_applicable(df):
    """ë°ì´í„°ì— ì í•©í•œ ì°¨íŠ¸ ìë™ ìƒì„±"""
    
    if len(df.columns) < 2:
        return None
    
    # ìˆ«ì ì»¬ëŸ¼ê³¼ ì¹´í…Œê³ ë¦¬ ì»¬ëŸ¼ ì‹ë³„
    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    
    if len(numeric_cols) >= 1 and len(categorical_cols) >= 1:
        # ë§‰ëŒ€ ì°¨íŠ¸ ìƒì„±
        fig = px.bar(
            df.head(20),  # ìµœëŒ€ 20ê°œ í•­ëª©
            x=categorical_cols[0],
            y=numeric_cols[0],
            title=f"{categorical_cols[0]}ë³„ {numeric_cols[0]}"
        )
        
        fig.update_layout(
            xaxis_title=categorical_cols[0],
            yaxis_title=numeric_cols[0],
            showlegend=False
        )
        
        return cl.Plotly(name="chart", figure=fig, display="inline")
    
    elif len(numeric_cols) >= 2:
        # ìŠ¤ìºí„° í”Œë¡¯ ìƒì„±
        fig = px.scatter(
            df.head(100),
            x=numeric_cols[0],
            y=numeric_cols[1],
            title=f"{numeric_cols[0]} vs {numeric_cols[1]}"
        )
        
        return cl.Plotly(name="chart", figure=fig, display="inline")
    
    return None

@cl.on_chat_end
async def end():
    """ì±„íŒ… ì„¸ì…˜ ì¢…ë£Œì‹œ ì •ë¦¬"""
    
    # ì„¸ì…˜ í†µê³„ ë¡œê¹…
    conversation_manager = cl.user_session.get("conversation_manager")
    if conversation_manager:
        session_stats = conversation_manager.get_session_statistics()
        print(f"ì„¸ì…˜ í†µê³„: {session_stats}")

# Chainlit ì•± ì‹¤í–‰
if __name__ == "__main__":
    cl.run()
```

### 4. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ë° ìµœì í™”

**ë„ë©”ì¸ íŠ¹í™” í”„ë¡¬í”„íŠ¸ ìµœì í™”:**
```python
class PromptOptimizer:
    """í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ë° ìµœì í™”"""
    
    def __init__(self):
        self.prompt_templates = {}
        self.performance_metrics = {}
    
    def create_specialized_prompts(self):
        """ìš©ë„ë³„ íŠ¹í™” í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        # ë§¤ì¶œ ë¶„ì„ íŠ¹í™” í”„ë¡¬í”„íŠ¸
        self.prompt_templates['revenue'] = """
ë‹¹ì‹ ì€ ê²Œì„ ë§¤ì¶œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¥´ì„¸ìš”:

1. ë§¤ì¶œ ê³„ì‚°ì‹œ currency='USD'ì¸ ê±°ë˜ë§Œ í¬í•¨
2. í™˜ë¶ˆëœ ê±°ë˜ëŠ” amount < 0 ìœ¼ë¡œ í‘œì‹œë¨
3. ì¼ë³„ ë§¤ì¶œì€ purchase_date ê¸°ì¤€ìœ¼ë¡œ GROUP BY
4. ë§¤ì¶œ ì„±ì¥ë¥  ê³„ì‚°ì‹œ ì „ë…„/ì „ì›” ë™ê¸° ëŒ€ë¹„ ì‚¬ìš©

ì§ˆë¬¸: {question}

ì¤‘ìš”í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­:
- ARPU (Average Revenue Per User): ì´ ë§¤ì¶œ / í™œì„± ì‚¬ìš©ì ìˆ˜
- ARPPU (Average Revenue Per Paying User): ì´ ë§¤ì¶œ / ê²°ì œ ì‚¬ìš©ì ìˆ˜
- LTV (Life Time Value): ì‚¬ìš©ìë‹¹ ì˜ˆìƒ ì´ ë§¤ì¶œ
"""

        # ì‚¬ìš©ì í–‰ë™ ë¶„ì„ íŠ¹í™” í”„ë¡¬í”„íŠ¸
        self.prompt_templates['user_behavior'] = """
ë‹¹ì‹ ì€ ê²Œì„ ì‚¬ìš©ì í–‰ë™ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒì„ ê³ ë ¤í•˜ì„¸ìš”:

1. í™œì„± ì‚¬ìš©ì: ìµœê·¼ 7ì¼ ë‚´ ë¡œê·¸ì¸í•œ ì‚¬ìš©ì
2. ì‹ ê·œ ì‚¬ìš©ì: registration_dateê°€ ì¡°íšŒ ê¸°ê°„ ë‚´ì¸ ì‚¬ìš©ì
3. ì´íƒˆ ì‚¬ìš©ì: ìµœê·¼ 30ì¼ê°„ ë¡œê·¸ì¸í•˜ì§€ ì•Šì€ ì‚¬ìš©ì
4. ì„¸ì…˜ ì‹œê°„: end_time - start_time (ì´ˆ ë‹¨ìœ„)

ì§ˆë¬¸: {question}

í•µì‹¬ ì§€í‘œ:
- DAU (Daily Active Users): ì¼ë³„ í™œì„± ì‚¬ìš©ì
- MAU (Monthly Active Users): ì›”ë³„ í™œì„± ì‚¬ìš©ì
- Retention Rate: ì‹ ê·œ ì‚¬ìš©ìì˜ ì¬ë°©ë¬¸ìœ¨
- Session Duration: í‰ê·  ì„¸ì…˜ ì§€ì† ì‹œê°„
"""

        # ì•„ì´í…œ/ì¸ë²¤í† ë¦¬ ë¶„ì„ íŠ¹í™” í”„ë¡¬í”„íŠ¸
        self.prompt_templates['items'] = """
ë‹¹ì‹ ì€ ê²Œì„ ì•„ì´í…œ ë° ì¸ë²¤í† ë¦¬ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤:

1. ì•„ì´í…œ ë“±ê¸‰: common, rare, epic, legendary ìˆœì„œ
2. ì•„ì´í…œ ì¹´í…Œê³ ë¦¬: weapon, armor, consumable, decoration
3. ì¸ê¸°ë„ ì¸¡ì •: êµ¬ë§¤ íšŸìˆ˜, ë§¤ì¶œ ê¸°ì—¬ë„, ì‚¬ìš© ë¹ˆë„
4. ê°€ê²© ë¶„ì„: USD ê¸°ì¤€ ê°€ê²©ëŒ€ë³„ ë¶„ë¥˜

ì§ˆë¬¸: {question}

ë¶„ì„ í¬ì¸íŠ¸:
- Best Sellers: íŒë§¤ëŸ‰ ê¸°ì¤€ ì¸ê¸° ì•„ì´í…œ
- Revenue Drivers: ë§¤ì¶œ ê¸°ì—¬ë„ ë†’ì€ ì•„ì´í…œ
- Price Elasticity: ê°€ê²© ë³€í™”ì— ë”°ë¥¸ ìˆ˜ìš” ë³€í™”
"""
    
    def select_optimal_prompt(self, question: str):
        """ì§ˆë¬¸ ë‚´ìš©ì— ë”°ë¥¸ ìµœì  í”„ë¡¬í”„íŠ¸ ì„ íƒ"""
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
        revenue_keywords = ['ë§¤ì¶œ', 'ìˆ˜ìµ', 'revenue', 'ê²°ì œ', 'êµ¬ë§¤', 'arpu', 'arppu']
        user_keywords = ['ì‚¬ìš©ì', 'ìœ ì €', 'user', 'í™œì„±', 'dau', 'mau', 'ì´íƒˆ', 'retention']
        item_keywords = ['ì•„ì´í…œ', 'item', 'ìƒí’ˆ', 'ì¸ë²¤í† ë¦¬', 'ì¥ë¹„', 'ë“±ê¸‰']
        
        question_lower = question.lower()
        
        if any(keyword in question_lower for keyword in revenue_keywords):
            return self.prompt_templates['revenue']
        elif any(keyword in question_lower for keyword in user_keywords):
            return self.prompt_templates['user_behavior']
        elif any(keyword in question_lower for keyword in item_keywords):
            return self.prompt_templates['items']
        else:
            return self.prompt_templates.get('general', self.create_general_prompt())
    
    def evaluate_prompt_performance(self, prompt_type: str, accuracy: float, execution_time: float):
        """í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ í‰ê°€ ë° ê¸°ë¡"""
        
        if prompt_type not in self.performance_metrics:
            self.performance_metrics[prompt_type] = {
                'accuracy_scores': [],
                'execution_times': [],
                'usage_count': 0
            }
        
        metrics = self.performance_metrics[prompt_type]
        metrics['accuracy_scores'].append(accuracy)
        metrics['execution_times'].append(execution_time)
        metrics['usage_count'] += 1
        
        # ì„±ëŠ¥ í†µê³„ ê³„ì‚°
        avg_accuracy = sum(metrics['accuracy_scores']) / len(metrics['accuracy_scores'])
        avg_execution_time = sum(metrics['execution_times']) / len(metrics['execution_times'])
        
        return {
            'prompt_type': prompt_type,
            'average_accuracy': avg_accuracy,
            'average_execution_time': avg_execution_time,
            'total_usage': metrics['usage_count']
        }
```

### 5. Langfuse í†µí•© ë¡œê¹… ë° ë¶„ì„

**LLM ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§:**
```python
from langfuse import Langfuse
from langfuse.decorators import langfuse_context, observe

class LangfuseIntegration:
    """Langfuseë¥¼ í†µí•œ LLM ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
    
    def __init__(self, public_key: str, secret_key: str):
        self.langfuse = Langfuse(
            public_key=public_key,
            secret_key=secret_key
        )
    
    @observe()
    def track_sql_generation(self, user_question: str, generated_sql: str, 
                           execution_success: bool, execution_time: float):
        """SQL ìƒì„± ê³¼ì • ì¶”ì """
        
        # ì„¸ì…˜ ìƒì„±
        trace = self.langfuse.trace(
            name="text-to-sql-generation",
            input={'user_question': user_question},
            output={'sql': generated_sql, 'success': execution_success},
            metadata={
                'execution_time': execution_time,
                'model': 'gpt-4',
                'domain': 'game_analytics'
            }
        )
        
        # ë‹¨ê³„ë³„ ìŠ¤íŒ¬ ìƒì„±
        with langfuse_context.update_current_trace(
            name="sql-generation",
            input={'question': user_question}
        ):
            # í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ë‹¨ê³„
            langfuse_context.update_current_span(
                name="prompt-engineering",
                input={'raw_question': user_question},
                output={'enhanced_prompt': 'enhanced_question'}
            )
            
            # LLM í˜¸ì¶œ ë‹¨ê³„
            langfuse_context.update_current_span(
                name="llm-call",
                model="gpt-4",
                input={'prompt': 'enhanced_question'},
                output={'sql': generated_sql}
            )
            
            # SQL ê²€ì¦ ë‹¨ê³„
            langfuse_context.update_current_span(
                name="sql-validation",
                input={'sql': generated_sql},
                output={'valid': execution_success}
            )
        
        return trace
    
    def analyze_performance_trends(self, days=30):
        """ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„"""
        
        # Langfuse APIë¥¼ í†µí•œ ë°ì´í„° ì¡°íšŒ
        traces = self.langfuse.get_traces(
            limit=1000,
            from_timestamp=datetime.now() - timedelta(days=days)
        )
        
        # ì„±ëŠ¥ ë¶„ì„
        performance_data = []
        for trace in traces:
            if trace.name == "text-to-sql-generation":
                performance_data.append({
                    'timestamp': trace.timestamp,
                    'success': trace.output.get('success', False),
                    'execution_time': trace.metadata.get('execution_time', 0),
                    'user_question': trace.input.get('user_question', ''),
                    'model': trace.metadata.get('model', 'unknown')
                })
        
        # í†µê³„ ê³„ì‚°
        df = pd.DataFrame(performance_data)
        
        analytics = {
            'total_queries': len(df),
            'success_rate': df['success'].mean() * 100,
            'avg_execution_time': df['execution_time'].mean(),
            'daily_usage': df.groupby(df['timestamp'].dt.date).size().to_dict(),
            'common_failures': self.analyze_failure_patterns(df[df['success'] == False])
        }
        
        return analytics
    
    def generate_improvement_recommendations(self, analytics):
        """ì„±ëŠ¥ ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        
        recommendations = []
        
        # ì„±ê³µë¥  ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if analytics['success_rate'] < 85:
            recommendations.append({
                'category': 'accuracy',
                'issue': f"ì„±ê³µë¥ ì´ {analytics['success_rate']:.1f}%ë¡œ ë‚®ìŒ",
                'recommendation': "í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê°œì„  ë° ìŠ¤í‚¤ë§ˆ ì •ë³´ ë³´ê°• í•„ìš”"
            })
        
        # ì‹¤í–‰ ì‹œê°„ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if analytics['avg_execution_time'] > 10:
            recommendations.append({
                'category': 'performance',
                'issue': f"í‰ê·  ì‹¤í–‰ ì‹œê°„ì´ {analytics['avg_execution_time']:.1f}ì´ˆë¡œ ëŠë¦¼",
                'recommendation': "ì¿¼ë¦¬ ìµœì í™” ë° ì¸ë±ìŠ¤ ê²€í†  í•„ìš”"
            })
        
        return recommendations
```

## ì„±ê³¼ ë° ì„íŒ©íŠ¸

### ì •ëŸ‰ì  ì„±ê³¼
- **ì—…ë¬´ íš¨ìœ¨ì„±**: ë°ì´í„° ì¶”ì¶œ ìš”ì²­ 40% ê°ì†Œ (ì›” í‰ê·  150ê±´ â†’ 90ê±´)
- **ì‘ë‹µ ì‹œê°„**: ê¸°ì¡´ ìˆ˜ë™ ì²˜ë¦¬ í‰ê·  2ì‹œê°„ â†’ AI ì‹œìŠ¤í…œ í‰ê·  30ì´ˆ
- **SQL ìƒì„± ì •í™•ë„**: 85% ì •í™•í•œ ì¿¼ë¦¬ ìƒì„± (ìˆ˜ì‘ì—… ê²€ì¦ ê¸°ì¤€)
- **ì‚¬ìš©ì ë§Œì¡±ë„**: 95% ì‚¬ìš©ì ë§Œì¡±ë„ ë‹¬ì„± (ì‚¬ìš©ì„± ì„¤ë¬¸ ì¡°ì‚¬ ê¸°ì¤€)

### ì •ì„±ì  íš¨ê³¼
- **ë°ì´í„° ë¯¼ì£¼í™”**: ë¹„ê°œë°œìë„ ë³µì¡í•œ ë¶„ì„ ì¿¼ë¦¬ ìˆ˜í–‰ ê°€ëŠ¥
- **í•™ìŠµ íš¨ê³¼**: ìƒì„±ëœ SQLì„ í†µí•œ ìì—°ìŠ¤ëŸ¬ìš´ SQL í•™ìŠµ í™˜ê²½ ì œê³µ
- **ì˜ì‚¬ê²°ì • ì†ë„**: ì‹¤ì‹œê°„ ë°ì´í„° ì¡°íšŒë¡œ ë¹ ë¥¸ ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì‚¬ê²°ì • ì§€ì›
- **ì—”ì§€ë‹ˆì–´ ìƒì‚°ì„±**: ë°˜ë³µì ì¸ ë°ì´í„° ì¶”ì¶œ ì—…ë¬´ì—ì„œ í•´ë°©ë˜ì–´ ê³ ë¶€ê°€ê°€ì¹˜ ì—…ë¬´ ì§‘ì¤‘

### ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜
- **ì¸ë ¥ ë¹„ìš© ì ˆê°**: ì›” 40ì‹œê°„ ì—…ë¬´ ì‹œê°„ ì ˆì•½ (ì•½ $2,000 ìƒë‹¹)
- **ë¶„ì„ ì ‘ê·¼ì„±**: ë°ì´í„° íŒ€ ì™¸ ì§ì›ë“¤ì˜ ë…ë¦½ì  ë¶„ì„ ëŠ¥ë ¥ í™•ë³´
- **í’ˆì§ˆ í–¥ìƒ**: í‘œì¤€í™”ëœ ì¿¼ë¦¬ í…œí”Œë¦¿ìœ¼ë¡œ ì¼ê´€ëœ ë¶„ì„ ê²°ê³¼
- **í™•ì¥ì„±**: ìƒˆë¡œìš´ ë„ë©”ì¸ ì§€ì‹ ì¶”ê°€ë¥¼ í†µí•œ ê¸°ëŠ¥ í™•ì¥ ê°€ëŠ¥

## ë°°ìš´ ì ê³¼ í–¥í›„ ê°œì„  ë°©í–¥

### ì£¼ìš” í•™ìŠµ ë‚´ìš©

1. **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì˜ ì¤‘ìš”ì„±**
   - ë„ë©”ì¸ íŠ¹í™” í”„ë¡¬í”„íŠ¸ê°€ ì¼ë°˜ì  í”„ë¡¬í”„íŠ¸ë³´ë‹¤ 30% ë†’ì€ ì •í™•ë„
   - ì»¨í…ìŠ¤íŠ¸ ì •ë³´ì˜ ì ì ˆí•œ ì–‘ê³¼ ì§ˆì´ ì„±ëŠ¥ì— ê²°ì •ì  ì˜í–¥

2. **ì‚¬ìš©ì ê²½í—˜ ì„¤ê³„ì˜ í•µì‹¬**
   - ì‹¤íŒ¨ ì¼€ì´ìŠ¤ì— ëŒ€í•œ ì¹œí™”ì  ì•ˆë‚´ê°€ ì‚¬ìš©ì ë§Œì¡±ë„ì— ì¤‘ìš”
   - ì‹œê°í™”ì™€ ì„¤ëª…ì´ ê²°í•©ëœ ê²°ê³¼ ì œì‹œì˜ íš¨ê³¼

3. **LLMì˜ í•œê³„ì™€ ë³´ì™„ ë°©ì•ˆ**
   - ë³µì¡í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì€ ì—¬ì „íˆ ì¸ê°„ì˜ ê²€ì¦ í•„ìš”
   - ë°˜ë³µ í•™ìŠµì„ í†µí•œ ë„ë©”ì¸ íŠ¹í™” ì„±ëŠ¥ í–¥ìƒ ê°€ëŠ¥

### ì•„ì‰¬ìš´ ì ê³¼ ê°œì„  ê³¼ì œ

#### í˜„ì¬ ì‹œìŠ¤í…œì˜ í•œê³„
1. **ë³µì¡í•œ ì¡°ì¸ ì¿¼ë¦¬**: 3ê°œ ì´ìƒ í…Œì´ë¸” ì¡°ì¸ ì‹œ ì •í™•ë„ í•˜ë½
2. **ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§**: ë³µì¡í•œ ê³„ì‚° ë¡œì§ì€ ì—¬ì „íˆ ìˆ˜ë™ ê°œì… í•„ìš”
3. **ì„±ëŠ¥ ìµœì í™”**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ì‘ë‹µ ì‹œê°„ ì§€ì—°
4. **ë‹¤êµ­ì–´ ì§€ì›**: í•œêµ­ì–´ ì§ˆë¬¸ì˜ ë¯¸ë¬˜í•œ ë‰˜ì•™ìŠ¤ ì´í•´ í•œê³„

#### í–¥í›„ ê°œì„  ê³„íš

**ë‹¨ê¸° ê°œì„  ì‚¬í•­ (3-6ê°œì›”)**
- **RAG ì‹œìŠ¤í…œ ë„ì…**: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í™œìš©í•œ ìŠ¤í‚¤ë§ˆ ì •ë³´ ê²€ìƒ‰ ê°•í™”
- **ì¿¼ë¦¬ ìºì‹±**: ìœ ì‚¬í•œ ì§ˆë¬¸ì— ëŒ€í•œ ê²°ê³¼ ìºì‹±ìœ¼ë¡œ ì‘ë‹µ ì†ë„ í–¥ìƒ
- **A/B í…ŒìŠ¤íŠ¸**: ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ ì „ëµì˜ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸

**ì¤‘ê¸° ê°œì„  ì‚¬í•­ (6-12ê°œì›”)**
- **íŒŒì¸íŠœë‹**: ê²Œì„ ë„ë©”ì¸ íŠ¹í™” ëª¨ë¸ íŒŒì¸íŠœë‹ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ
- **ë©€í‹°ëª¨ë‹¬**: ì°¨íŠ¸ë‚˜ ê·¸ë˜í”„ ê¸°ë°˜ ì§ˆë¬¸ ì§€ì›
- **ì‹¤ì‹œê°„ í•™ìŠµ**: ì‚¬ìš©ì í”¼ë“œë°±ì„ í†µí•œ ì§€ì†ì  ëª¨ë¸ ê°œì„ 

**ì¥ê¸° ë¹„ì „ (1-2ë…„)**
- **ì™„ì „ ìë™í™”**: ë³µì¡í•œ ë¶„ì„ ë³´ê³ ì„œ ìë™ ìƒì„±
- **ì˜ˆì¸¡ ë¶„ì„**: ë‹¨ìˆœ ì¡°íšŒë¥¼ ë„˜ì–´ì„  ì˜ˆì¸¡ ë¶„ì„ ê¸°ëŠ¥
- **ìì—°ì–´ ëŒ€ì‹œë³´ë“œ**: ìŒì„± ëª…ë ¹ì„ í†µí•œ ëŒ€ì‹œë³´ë“œ ì œì–´

### ê¸°ìˆ  ìŠ¤íƒ ì§„í™” ë°©í–¥
- **LangGraph**: ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ìœ„í•œ ê·¸ë˜í”„ ê¸°ë°˜ ì—ì´ì „íŠ¸
- **Streamlit**: ë” í’ë¶€í•œ ì‹œê°í™”ë¥¼ ìœ„í•œ ëŒ€ì‹œë³´ë“œ í†µí•©
- **Vector Database**: Pinecone/Weaviateë¥¼ í™œìš©í•œ ê³ ë„í™”ëœ RAG ì‹œìŠ¤í…œ

ì´ í”„ë¡œì íŠ¸ë¥¼ í†µí•´ LLMì„ í™œìš©í•œ ì‹¤ìš©ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ì†”ë£¨ì…˜ êµ¬ì¶• ê²½í—˜ì„ ìŒ“ì•˜ìœ¼ë©°, AI ê¸°ìˆ ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ì ìš©ì—ì„œ ì¤‘ìš”í•œ ê²ƒì€ ê¸°ìˆ ì  ì •í™•ì„±ë¿ë§Œ ì•„ë‹ˆë¼ ì‚¬ìš©ì ê²½í—˜ê³¼ ì‹¤ë¬´ ì ìš©ì„±ì„ì„ ê¹¨ë‹¬ì•˜ìŠµë‹ˆë‹¤. íŠ¹íˆ "ì™„ë²½í•˜ì§€ ì•Šë”ë¼ë„ ìœ ìš©í•œ" ì†”ë£¨ì…˜ì˜ ê°€ì¹˜ë¥¼ ê²½í—˜í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.
