<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>다양한 데이터 소스 통합 | SeungHo Choi</title>
    
    <!-- Favicon -->
    <link rel="icon" type="image/x-icon" href="/static/favicon.ico">
    <link rel="icon" type="image/png" sizes="32x32" href="/static/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/static/favicon-16x16.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/static/favicon-256x256.png">
    
    <!-- Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <!-- Prism.js for code highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
    
    <style>
        body { font-family: 'Inter', sans-serif; }
        .gradient-bg { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); }
        
        /* 마크다운 스타일링 */
        .prose {
            max-width: none;
            color: #374151;
            line-height: 1.75;
        }
        
        .prose h1 {
            font-size: 2.5rem;
            font-weight: 800;
            color: #1f2937;
            margin-bottom: 2rem;
            margin-top: 3rem;
            padding-bottom: 0.75rem;
            border-bottom: 3px solid #3b82f6;
        }
        
        .prose h2 {
            font-size: 2rem;
            font-weight: 700;
            color: #1f2937;
            margin-bottom: 1.5rem;
            margin-top: 2.5rem;
            padding-bottom: 0.5rem;
            border-bottom: 2px solid #e5e7eb;
            position: relative;
        }
        
        .prose h2::before {
            content: '';
            position: absolute;
            bottom: -2px;
            left: 0;
            width: 60px;
            height: 2px;
            background: #3b82f6;
        }
        
        .prose h3 {
            font-size: 1.5rem;
            font-weight: 600;
            color: #374151;
            margin-bottom: 1rem;
            margin-top: 2rem;
        }
        
        .prose h4 {
            font-size: 1.25rem;
            font-weight: 600;
            color: #4b5563;
            margin-bottom: 0.75rem;
            margin-top: 1.5rem;
        }
        
        .prose p {
            margin-bottom: 1.5rem;
            color: #4b5563;
            line-height: 1.8;
        }
        
        .prose ul, .prose ol {
            margin-bottom: 1.5rem;
            padding-left: 1.5rem;
        }
        
        .prose li {
            margin-bottom: 0.5rem;
            color: #4b5563;
            line-height: 1.7;
        }
        
        .prose ul li {
            position: relative;
            list-style: none;
        }
        
        .prose ul li::before {
            content: '•';
            color: #3b82f6;
            font-weight: bold;
            position: absolute;
            left: -1rem;
        }
        
        .prose ol li {
            list-style: decimal;
            color: #4b5563;
        }
        
        .prose strong {
            font-weight: 600;
            color: #1f2937;
        }
        
        .prose em {
            font-style: italic;
            color: #6b7280;
        }
        
        .prose blockquote {
            border-left: 4px solid #3b82f6;
            padding-left: 1.5rem;
            margin: 2rem 0;
            background: #f8fafc;
            padding: 1.5rem;
            border-radius: 0.5rem;
            font-style: italic;
            color: #4b5563;
        }
        
        .prose code {
            background: #f1f5f9;
            color: #e11d48;
            padding: 0.25rem 0.5rem;
            border-radius: 0.375rem;
            font-size: 0.875rem;
            font-weight: 500;
            border: 1px solid #e2e8f0;
        }
        
        .prose pre {
            background: #1e293b !important;
            color: #e2e8f0 !important;
            padding: 1.5rem !important;
            border-radius: 0.75rem !important;
            overflow-x: auto !important;
            margin: 2rem 0 !important;
            border: 1px solid #334155 !important;
            box-shadow: 0 10px 25px -5px rgba(0, 0, 0, 0.1) !important;
        }
        
        .prose pre code {
            background: transparent !important;
            color: inherit !important;
            padding: 0 !important;
            border: none !important;
            border-radius: 0 !important;
            font-size: 0.875rem !important;
        }
        
        .prose img {
            border-radius: 0.75rem;
            box-shadow: 0 10px 25px -5px rgba(0, 0, 0, 0.1);
            margin: 2rem 0;
            max-width: 100%;
            height: auto;
            cursor: zoom-in;
            transition: transform 0.3s ease;
        }

        .prose img:hover {
            transform: scale(1.02);
        }
        
        .prose table {
            width: 100%;
            border-collapse: collapse;
            margin: 2rem 0;
            background: white;
            border-radius: 0.5rem;
            overflow: hidden;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
        }
        
        .prose th {
            background: #f8fafc;
            padding: 1rem;
            text-align: left;
            font-weight: 600;
            color: #374151;
            border-bottom: 2px solid #e5e7eb;
        }
        
        .prose td {
            padding: 1rem;
            border-bottom: 1px solid #f3f4f6;
            color: #4b5563;
        }
        
        .prose hr {
            border: none;
            height: 2px;
            background: linear-gradient(to right, #3b82f6, #8b5cf6);
            margin: 3rem 0;
            border-radius: 1px;
        }
        
        /* 특별한 강조 박스 */
        .prose p:has(strong:first-child) {
            background: linear-gradient(135deg, #eff6ff 0%, #f0f9ff 100%);
            border-left: 4px solid #3b82f6;
            padding: 1rem 1.5rem;
            border-radius: 0.5rem;
            margin: 1.5rem 0;
        }
    </style>
</head>
<body class="bg-gray-50">
    
    <!-- Navigation -->
    <nav class="bg-white shadow-sm border-b sticky top-0 z-50">
        <div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8">
            <div class="flex justify-between items-center py-4">
                <a href="/" class="text-xl font-bold text-gray-800 hover:text-blue-600 transition-colors">
                    <i class="fas fa-arrow-left mr-2"></i> SeungHo Choi
                </a>
                <div class="flex space-x-4">
                    <!-- GitHub 링크 제거됨 -->
                </div>
            </div>
        </div>
    </nav>

    <!-- Project Header -->
    <section class="gradient-bg text-white py-20">
        <div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8">
            <div class="text-center">
                <h1 class="text-4xl md:text-5xl font-bold mb-6 leading-tight">다양한 데이터 소스 통합</h1>
                <p class="text-xl text-white/90 mb-8 leading-relaxed">ElasticSearch, Google/Apple 마켓, Prometheus, Redis, SensorTower 등 15개 이상의 다양한 외부 데이터 소스를 안정적으로 수집하는 ETL 구축</p>
                <div class="flex justify-center items-center space-x-8 text-white/80">
                    <span class="flex items-center">
                        <i class="fas fa-calendar mr-2"></i>2021.01 - 
                    </span>
                </div>
            </div>
        </div>
    </section>

    <!-- Project Content -->
    <section class="py-20">
        <div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8">
            
            <!-- Tech Stack -->
            <div class="bg-white rounded-2xl p-8 shadow-lg mb-8 border border-gray-100">
                <h2 class="text-2xl font-bold mb-6 text-gray-800 flex items-center">
                    <i class="fas fa-tools mr-3 text-blue-600"></i>
                    기술 스택
                </h2>
                <div class="flex flex-wrap gap-3">
                    
                    <span class="px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 text-blue-800 rounded-full font-medium border border-blue-200 hover:shadow-md transition-shadow">
                        Prefect
                    </span>
                    
                    <span class="px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 text-blue-800 rounded-full font-medium border border-blue-200 hover:shadow-md transition-shadow">
                        ElasticSearch
                    </span>
                    
                    <span class="px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 text-blue-800 rounded-full font-medium border border-blue-200 hover:shadow-md transition-shadow">
                        Redis
                    </span>
                    
                    <span class="px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 text-blue-800 rounded-full font-medium border border-blue-200 hover:shadow-md transition-shadow">
                        Prometheus
                    </span>
                    
                    <span class="px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 text-blue-800 rounded-full font-medium border border-blue-200 hover:shadow-md transition-shadow">
                        RDS Snapshot
                    </span>
                    
                    <span class="px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 text-blue-800 rounded-full font-medium border border-blue-200 hover:shadow-md transition-shadow">
                        API Integration
                    </span>
                    
                </div>
            </div>

            <!-- Project Details -->
            <div class="bg-white rounded-2xl p-8 shadow-lg border border-gray-100">
                <div class="prose prose-lg max-w-none">
                    <h1>다양한 데이터 소스 통합 플랫폼</h1>
<h2>프로젝트 개요</h2>
<p>ElasticSearch, Google/Apple 마켓, Prometheus, Redis, SensorTower 등 15개 이상의 다양한 외부 데이터 소스를 안정적으로 수집하고 통합하는 ETL 플랫폼을 구축했습니다. 각 데이터 소스의 고유한 특성과 제약사항을 고려한 맞춤형 수집 전략을 수립하여 포괄적인 데이터 생태계를 구축했습니다.</p>
<p><strong>핵심 성과:</strong>
- 15개 이상 다양한 데이터 소스 통합 수집
- 마켓 데이터 실시간 수집으로 경쟁 분석 역량 강화
- 시계열 데이터 처리로 인프라 모니터링 고도화
- 환율/GeoIP 데이터 통합으로 글로벌 분석 지원</p>
<h2>프로젝트 목표</h2>
<h3>비즈니스 요구사항</h3>
<ol>
<li><strong>포괄적 데이터 수집</strong>: 게임 비즈니스에 필요한 모든 외부 데이터 통합</li>
<li><strong>경쟁사 분석</strong>: 마켓 데이터를 통한 실시간 경쟁사 모니터링</li>
<li><strong>글로벌 서비스</strong>: 다국가 서비스를 위한 지역별 데이터 수집</li>
<li><strong>운영 최적화</strong>: 인프라 메트릭을 통한 시스템 최적화</li>
</ol>
<h3>기술적 목표</h3>
<ul>
<li>다양한 API 제약사항을 고려한 안정적 데이터 수집</li>
<li>실시간 및 배치 처리의 하이브리드 아키텍처 구축</li>
<li>데이터 품질 보장을 위한 검증 및 모니터링 시스템</li>
<li>확장 가능한 플러그인 기반 수집 프레임워크</li>
</ul>
<h2>기술적 도전과 해결 과정</h2>
<h3>1. 통합 데이터 수집 아키텍처</h3>
<p><strong>도전 과제:</strong>
- 각기 다른 API 스펙과 제약사항
- 데이터 형식과 스키마의 다양성
- 실시간성과 안정성의 균형</p>
<p><strong>해결 방안:</strong></p>
<pre class="codehilite"><code>Multi-Source Data Collection Architecture
├── Data Source Connectors
│   ├── ElasticSearch ETL
│   ├── Google/Apple Store APIs
│   ├── Prometheus Metrics
│   ├── Redis Data Export
│   ├── SensorTower API
│   ├── Currency Exchange APIs
│   ├── GeoIP Databases
│   └── RDS Snapshot Processing
├── Collection Framework
│   ├── Scheduler (Prefect)
│   ├── Rate Limiter
│   ├── Retry Handler
│   └── Data Validator
├── Processing Layer
│   ├── Real-time Stream (Kafka)
│   ├── Batch Processing (Lambda)
│   └── Data Transformation
└── Storage &amp; Analytics
    ├── Data Lake (S3)
    ├── Data Warehouse (Redshift)
    └── Monitoring (CloudWatch)
</code></pre>

<h3>2. ElasticSearch ETL 시스템</h3>
<p><strong>복잡한 로그 데이터 처리:</strong></p>
<pre class="codehilite"><code class="language-python">from elasticsearch import Elasticsearch
import pandas as pd
from datetime import datetime, timedelta
import json

class ElasticSearchETL:
    &quot;&quot;&quot;ElasticSearch 데이터 추출 및 변환&quot;&quot;&quot;

    def __init__(self, es_hosts, auth_config):
        self.es_client = Elasticsearch(
            hosts=es_hosts,
            http_auth=(auth_config['username'], auth_config['password']),
            verify_certs=True,
            timeout=30,
            max_retries=3
        )

    def extract_game_logs(self, start_date, end_date, batch_size=10000):
        &quot;&quot;&quot;게임 로그 데이터 배치 추출&quot;&quot;&quot;

        query = {
            &quot;query&quot;: {
                &quot;bool&quot;: {
                    &quot;must&quot;: [
                        {
                            &quot;range&quot;: {
                                &quot;@timestamp&quot;: {
                                    &quot;gte&quot;: start_date.isoformat(),
                                    &quot;lte&quot;: end_date.isoformat()
                                }
                            }
                        }
                    ],
                    &quot;filter&quot;: [
                        {&quot;term&quot;: {&quot;log_type&quot;: &quot;game_event&quot;}},
                        {&quot;exists&quot;: {&quot;field&quot;: &quot;user_id&quot;}},
                        {&quot;exists&quot;: {&quot;field&quot;: &quot;event_type&quot;}}
                    ]
                }
            },
            &quot;sort&quot;: [{&quot;@timestamp&quot;: {&quot;order&quot;: &quot;asc&quot;}}],
            &quot;size&quot;: batch_size
        }

        # 스크롤 검색으로 대용량 데이터 처리
        response = self.es_client.search(
            index=&quot;game-logs-*&quot;,
            body=query,
            scroll=&quot;5m&quot;
        )

        scroll_id = response['_scroll_id']
        hits = response['hits']['hits']

        all_documents = []

        while hits:
            # 문서 처리
            for hit in hits:
                doc = self.transform_elasticsearch_doc(hit['_source'])
                all_documents.append(doc)

            # 다음 배치 가져오기
            response = self.es_client.scroll(
                scroll_id=scroll_id,
                scroll=&quot;5m&quot;
            )
            hits = response['hits']['hits']

        # 스크롤 컨텍스트 정리
        self.es_client.clear_scroll(scroll_id=scroll_id)

        return all_documents

    def transform_elasticsearch_doc(self, doc):
        &quot;&quot;&quot;ElasticSearch 문서를 정규화된 형태로 변환&quot;&quot;&quot;

        try:
            # 기본 필드 추출
            transformed = {
                'timestamp': doc.get('@timestamp'),
                'user_id': doc.get('user_id'),
                'session_id': doc.get('session_id'),
                'event_type': doc.get('event_type'),
                'game_version': doc.get('game_version', 'unknown'),
                'platform': doc.get('platform', 'unknown'),
                'country': doc.get('geoip', {}).get('country_code2', 'unknown')
            }

            # 이벤트별 특화 데이터 처리
            event_type = doc.get('event_type')

            if event_type == 'game_start':
                transformed.update({
                    'game_mode': doc.get('game_mode'),
                    'difficulty': doc.get('difficulty'),
                    'character_level': doc.get('character_level')
                })

            elif event_type == 'purchase':
                transformed.update({
                    'item_id': doc.get('item_id'),
                    'amount': float(doc.get('amount', 0)),
                    'currency': doc.get('currency'),
                    'payment_method': doc.get('payment_method')
                })

            elif event_type == 'error':
                transformed.update({
                    'error_code': doc.get('error_code'),
                    'error_message': doc.get('error_message'),
                    'stack_trace': doc.get('stack_trace')
                })

            # JSON 필드를 문자열로 직렬화
            if 'custom_data' in doc:
                transformed['custom_data'] = json.dumps(doc['custom_data'])

            return transformed

        except Exception as e:
            print(f&quot;문서 변환 오류: {e}&quot;)
            return None

    def extract_error_analytics(self, days=7):
        &quot;&quot;&quot;에러 로그 분석을 위한 특화 추출&quot;&quot;&quot;

        end_date = datetime.utcnow()
        start_date = end_date - timedelta(days=days)

        aggregation_query = {
            &quot;query&quot;: {
                &quot;bool&quot;: {
                    &quot;must&quot;: [
                        {&quot;term&quot;: {&quot;log_level&quot;: &quot;ERROR&quot;}},
                        {
                            &quot;range&quot;: {
                                &quot;@timestamp&quot;: {
                                    &quot;gte&quot;: start_date.isoformat(),
                                    &quot;lte&quot;: end_date.isoformat()
                                }
                            }
                        }
                    ]
                }
            },
            &quot;aggs&quot;: {
                &quot;error_by_type&quot;: {
                    &quot;terms&quot;: {&quot;field&quot;: &quot;error_code.keyword&quot;, &quot;size&quot;: 50}
                },
                &quot;error_by_platform&quot;: {
                    &quot;terms&quot;: {&quot;field&quot;: &quot;platform.keyword&quot;, &quot;size&quot;: 10}
                },
                &quot;error_trend&quot;: {
                    &quot;date_histogram&quot;: {
                        &quot;field&quot;: &quot;@timestamp&quot;,
                        &quot;fixed_interval&quot;: &quot;1h&quot;
                    }
                }
            },
            &quot;size&quot;: 0
        }

        response = self.es_client.search(
            index=&quot;game-logs-*&quot;,
            body=aggregation_query
        )

        return {
            'total_errors': response['hits']['total']['value'],
            'error_by_type': response['aggregations']['error_by_type']['buckets'],
            'error_by_platform': response['aggregations']['error_by_platform']['buckets'],
            'hourly_trend': response['aggregations']['error_trend']['buckets']
        }
</code></pre>

<h3>3. Google/Apple 마켓 데이터 수집</h3>
<p><strong>앱스토어 데이터 모니터링:</strong></p>
<pre class="codehilite"><code class="language-python">import requests
import time
from typing import Dict, List
import json

class AppStoreDataCollector:
    &quot;&quot;&quot;Google Play Store 및 Apple App Store 데이터 수집&quot;&quot;&quot;

    def __init__(self, config):
        self.google_api_key = config['google_api_key']
        self.apple_connect_key = config['apple_connect_key']
        self.rate_limiter = RateLimiter()

    def collect_google_play_data(self, app_id: str):
        &quot;&quot;&quot;Google Play Store 앱 정보 수집&quot;&quot;&quot;

        endpoints = {
            'details': f'https://play.googleapis.com/androidpublisher/v3/applications/{app_id}/details',
            'reviews': f'https://play.googleapis.com/androidpublisher/v3/applications/{app_id}/reviews',
            'stats': f'https://play.googleapis.com/androidpublisher/v3/applications/{app_id}/stats'
        }

        collected_data = {}

        for data_type, url in endpoints.items():
            try:
                # Rate limiting 적용
                self.rate_limiter.wait_if_needed('google_play')

                headers = {
                    'Authorization': f'Bearer {self.google_api_key}',
                    'Content-Type': 'application/json'
                }

                response = requests.get(url, headers=headers, timeout=30)
                response.raise_for_status()

                collected_data[data_type] = response.json()

                # API 사용량 기록
                self.rate_limiter.record_request('google_play')

            except requests.exceptions.RequestException as e:
                print(f&quot;Google Play API 오류 ({data_type}): {e}&quot;)
                collected_data[data_type] = None

        return self.transform_google_play_data(collected_data, app_id)

    def collect_apple_appstore_data(self, app_id: str):
        &quot;&quot;&quot;Apple App Store 데이터 수집&quot;&quot;&quot;

        # iTunes Search API (공개 API)
        search_url = f'https://itunes.apple.com/lookup?id={app_id}'

        try:
            response = requests.get(search_url, timeout=30)
            response.raise_for_status()

            data = response.json()

            if data['resultCount'] &gt; 0:
                app_info = data['results'][0]
                return self.transform_apple_data(app_info)

        except requests.exceptions.RequestException as e:
            print(f&quot;Apple App Store API 오류: {e}&quot;)

        return None

    def transform_google_play_data(self, raw_data: Dict, app_id: str):
        &quot;&quot;&quot;Google Play 데이터 정규화&quot;&quot;&quot;

        details = raw_data.get('details', {})
        reviews = raw_data.get('reviews', {})
        stats = raw_data.get('stats', {})

        return {
            'platform': 'google_play',
            'app_id': app_id,
            'app_name': details.get('title'),
            'developer': details.get('developer', {}).get('name'),
            'category': details.get('category'),
            'rating': details.get('aggregateRating', {}).get('starRating'),
            'review_count': details.get('aggregateRating', {}).get('ratingCount'),
            'install_count': details.get('installs'),
            'price': details.get('price', {}).get('micros', 0) / 1000000,
            'currency': details.get('price', {}).get('currency'),
            'last_updated': details.get('lastUpdateTime'),
            'version': details.get('versionCode'),
            'recent_reviews': self.extract_recent_reviews(reviews),
            'download_stats': stats.get('downloads', {}),
            'collected_at': datetime.utcnow().isoformat()
        }

    def extract_recent_reviews(self, reviews_data: Dict):
        &quot;&quot;&quot;최근 리뷰 추출 및 감정 분석&quot;&quot;&quot;

        reviews = reviews_data.get('reviews', [])
        recent_reviews = []

        for review in reviews[:50]:  # 최근 50개 리뷰
            review_info = {
                'review_id': review.get('reviewId'),
                'author': review.get('authorName'),
                'rating': review.get('starRating'),
                'text': review.get('text'),
                'posted_date': review.get('postedDate'),
                'helpful_count': review.get('thumbsUpCount', 0),
                'version': review.get('version')
            }

            # 간단한 감정 분석
            sentiment = self.analyze_sentiment(review.get('text', ''))
            review_info['sentiment'] = sentiment

            recent_reviews.append(review_info)

        return recent_reviews

    def analyze_sentiment(self, text: str):
        &quot;&quot;&quot;간단한 키워드 기반 감정 분석&quot;&quot;&quot;

        positive_keywords = ['good', 'great', 'excellent', 'amazing', 'love', 'perfect']
        negative_keywords = ['bad', 'terrible', 'awful', 'hate', 'horrible', 'worst']

        text_lower = text.lower()

        positive_count = sum(1 for word in positive_keywords if word in text_lower)
        negative_count = sum(1 for word in negative_keywords if word in text_lower)

        if positive_count &gt; negative_count:
            return 'positive'
        elif negative_count &gt; positive_count:
            return 'negative'
        else:
            return 'neutral'

class RateLimiter:
    &quot;&quot;&quot;API Rate Limiting 관리&quot;&quot;&quot;

    def __init__(self):
        self.request_history = {}
        self.limits = {
            'google_play': {'requests_per_minute': 100, 'requests_per_hour': 1000},
            'apple_store': {'requests_per_minute': 20, 'requests_per_hour': 200},
            'sensorTower': {'requests_per_minute': 10, 'requests_per_hour': 100}
        }

    def wait_if_needed(self, api_name: str):
        &quot;&quot;&quot;필요시 대기하여 Rate Limit 준수&quot;&quot;&quot;

        if api_name not in self.request_history:
            self.request_history[api_name] = []

        now = time.time()
        history = self.request_history[api_name]

        # 1분 전 요청 정리
        minute_ago = now - 60
        history = [req_time for req_time in history if req_time &gt; minute_ago]

        # 분당 제한 확인
        minute_limit = self.limits[api_name]['requests_per_minute']
        if len(history) &gt;= minute_limit:
            sleep_time = 60 - (now - history[0])
            if sleep_time &gt; 0:
                print(f&quot;{api_name} Rate limit - {sleep_time:.1f}초 대기&quot;)
                time.sleep(sleep_time)

    def record_request(self, api_name: str):
        &quot;&quot;&quot;요청 기록&quot;&quot;&quot;
        if api_name not in self.request_history:
            self.request_history[api_name] = []

        self.request_history[api_name].append(time.time())
</code></pre>

<h3>4. Prometheus 시계열 데이터 처리</h3>
<p><strong>인프라 메트릭 수집 및 분석:</strong></p>
<pre class="codehilite"><code class="language-python">import requests
from prometheus_client.parser import text_string_to_metric_families
import pandas as pd
from datetime import datetime, timedelta

class PrometheusDataCollector:
    &quot;&quot;&quot;Prometheus 메트릭 수집 및 처리&quot;&quot;&quot;

    def __init__(self, prometheus_url: str):
        self.prometheus_url = prometheus_url.rstrip('/')
        self.session = requests.Session()

    def query_range(self, query: str, start_time: datetime, 
                   end_time: datetime, step: str = '1m'):
        &quot;&quot;&quot;시간 범위 쿼리 실행&quot;&quot;&quot;

        url = f&quot;{self.prometheus_url}/api/v1/query_range&quot;

        params = {
            'query': query,
            'start': start_time.timestamp(),
            'end': end_time.timestamp(),
            'step': step
        }

        try:
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()

            data = response.json()

            if data['status'] == 'success':
                return self.transform_prometheus_data(data['data'])
            else:
                print(f&quot;Prometheus 쿼리 실패: {data.get('error', 'Unknown error')}&quot;)
                return None

        except requests.exceptions.RequestException as e:
            print(f&quot;Prometheus API 오류: {e}&quot;)
            return None

    def collect_infrastructure_metrics(self, hours: int = 24):
        &quot;&quot;&quot;인프라 핵심 메트릭 수집&quot;&quot;&quot;

        end_time = datetime.utcnow()
        start_time = end_time - timedelta(hours=hours)

        metrics_queries = {
            'cpu_usage': 'avg(100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=&quot;idle&quot;}[5m])) * 100))',
            'memory_usage': 'avg((node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100)',
            'disk_usage': 'avg(100 - ((node_filesystem_avail_bytes{mountpoint=&quot;/&quot;} / node_filesystem_size_bytes{mountpoint=&quot;/&quot;}) * 100))',
            'network_in': 'sum(rate(node_network_receive_bytes_total[5m]))',
            'network_out': 'sum(rate(node_network_transmit_bytes_total[5m]))',
            'load_average': 'avg(node_load1)',
            'redis_memory': 'redis_memory_used_bytes',
            'redis_connected_clients': 'redis_connected_clients',
            'mysql_connections': 'mysql_global_status_threads_connected',
            'mysql_queries_per_second': 'rate(mysql_global_status_questions[5m])'
        }

        collected_metrics = {}

        for metric_name, query in metrics_queries.items():
            print(f&quot;수집 중: {metric_name}&quot;)
            data = self.query_range(query, start_time, end_time)

            if data:
                collected_metrics[metric_name] = data

        return self.create_metrics_summary(collected_metrics)

    def transform_prometheus_data(self, prometheus_data):
        &quot;&quot;&quot;Prometheus 응답 데이터를 DataFrame으로 변환&quot;&quot;&quot;

        result_type = prometheus_data.get('resultType')

        if result_type == 'matrix':
            all_data = []

            for result in prometheus_data['result']:
                metric = result['metric']
                values = result['values']

                for timestamp, value in values:
                    data_point = {
                        'timestamp': datetime.fromtimestamp(timestamp),
                        'value': float(value)
                    }

                    # 메트릭 라벨 추가
                    for label, label_value in metric.items():
                        data_point[f'label_{label}'] = label_value

                    all_data.append(data_point)

            return pd.DataFrame(all_data)

        elif result_type == 'vector':
            data = []
            for result in prometheus_data['result']:
                metric = result['metric']
                timestamp, value = result['value']

                data_point = {
                    'timestamp': datetime.fromtimestamp(timestamp),
                    'value': float(value)
                }

                for label, label_value in metric.items():
                    data_point[f'label_{label}'] = label_value

                data.append(data_point)

            return pd.DataFrame(data)

        return None

    def create_metrics_summary(self, metrics_data):
        &quot;&quot;&quot;메트릭 데이터 요약 통계 생성&quot;&quot;&quot;

        summary = {}

        for metric_name, df in metrics_data.items():
            if df is not None and not df.empty:
                summary[metric_name] = {
                    'avg': df['value'].mean(),
                    'max': df['value'].max(),
                    'min': df['value'].min(),
                    'current': df['value'].iloc[-1] if len(df) &gt; 0 else None,
                    'trend': self.calculate_trend(df['value']),
                    'data_points': len(df)
                }

        return summary

    def calculate_trend(self, values):
        &quot;&quot;&quot;간단한 트렌드 계산&quot;&quot;&quot;
        if len(values) &lt; 2:
            return 'insufficient_data'

        first_half = values[:len(values)//2].mean()
        second_half = values[len(values)//2:].mean()

        change_pct = ((second_half - first_half) / first_half) * 100

        if change_pct &gt; 5:
            return 'increasing'
        elif change_pct &lt; -5:
            return 'decreasing'
        else:
            return 'stable'
</code></pre>

<h3>5. 통합 데이터 파이프라인 관리</h3>
<p><strong>Prefect 기반 워크플로우 오케스트레이션:</strong></p>
<pre class="codehilite"><code class="language-python">from prefect import flow, task
from prefect.task_runners import ConcurrentTaskRunner
import boto3
from datetime import datetime, timedelta

@task
def collect_elasticsearch_data(start_date, end_date):
    &quot;&quot;&quot;ElasticSearch 데이터 수집 태스크&quot;&quot;&quot;
    collector = ElasticSearchETL(es_config)
    return collector.extract_game_logs(start_date, end_date)

@task
def collect_app_store_data(app_ids):
    &quot;&quot;&quot;앱스토어 데이터 수집 태스크&quot;&quot;&quot;
    collector = AppStoreDataCollector(market_config)
    results = {}

    for app_id in app_ids:
        google_data = collector.collect_google_play_data(app_id)
        apple_data = collector.collect_apple_appstore_data(app_id)

        results[app_id] = {
            'google_play': google_data,
            'apple_store': apple_data
        }

    return results

@task
def collect_prometheus_metrics():
    &quot;&quot;&quot;Prometheus 메트릭 수집 태스크&quot;&quot;&quot;
    collector = PrometheusDataCollector(prometheus_config['url'])
    return collector.collect_infrastructure_metrics(hours=1)

@task
def collect_redis_data():
    &quot;&quot;&quot;Redis 데이터 내보내기 태스크&quot;&quot;&quot;
    redis_collector = RedisDataExporter(redis_config)
    return redis_collector.export_game_cache_data()

@task
def collect_currency_rates():
    &quot;&quot;&quot;환율 데이터 수집 태스크&quot;&quot;&quot;
    currency_collector = CurrencyRateCollector(currency_api_key)
    return currency_collector.get_latest_rates(['USD', 'EUR', 'JPY', 'CNY', 'KRW'])

@task
def collect_geoip_data():
    &quot;&quot;&quot;GeoIP 데이터 업데이트 태스크&quot;&quot;&quot;
    geoip_collector = GeoIPDataCollector()
    return geoip_collector.update_database()

@task
def validate_and_transform_data(raw_data):
    &quot;&quot;&quot;데이터 검증 및 변환 태스크&quot;&quot;&quot;
    validator = DataQualityValidator()
    transformer = DataTransformer()

    # 데이터 품질 검증
    validation_results = validator.validate_all_sources(raw_data)

    # 데이터 변환 및 정규화
    transformed_data = transformer.transform_all_sources(raw_data)

    return {
        'data': transformed_data,
        'validation': validation_results
    }

@task
def store_to_data_lake(processed_data):
    &quot;&quot;&quot;데이터 레이크 저장 태스크&quot;&quot;&quot;
    s3_client = boto3.client('s3')

    timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')

    for source_name, data in processed_data['data'].items():
        key = f&quot;external_data/{source_name}/year={datetime.now().year}/month={datetime.now().month:02d}/day={datetime.now().day:02d}/{timestamp}.parquet&quot;

        # Parquet 형태로 저장
        df = pd.DataFrame(data)

        buffer = io.BytesIO()
        df.to_parquet(buffer, index=False)

        s3_client.put_object(
            Bucket='data-lake-bucket',
            Key=key,
            Body=buffer.getvalue(),
            ContentType='application/octet-stream'
        )

@flow(task_runner=ConcurrentTaskRunner())
def external_data_collection_flow():
    &quot;&quot;&quot;외부 데이터 수집 메인 플로우&quot;&quot;&quot;

    # 수집 기간 설정
    end_date = datetime.utcnow()
    start_date = end_date - timedelta(hours=1)

    # 병렬 데이터 수집
    elasticsearch_future = collect_elasticsearch_data.submit(start_date, end_date)
    app_store_future = collect_app_store_data.submit(['com.company.game1', 'com.company.game2'])
    prometheus_future = collect_prometheus_metrics.submit()
    redis_future = collect_redis_data.submit()
    currency_future = collect_currency_rates.submit()
    geoip_future = collect_geoip_data.submit()

    # 결과 수집
    raw_data = {
        'elasticsearch': elasticsearch_future.result(),
        'app_stores': app_store_future.result(),
        'prometheus': prometheus_future.result(),
        'redis': redis_future.result(),
        'currency': currency_future.result(),
        'geoip': geoip_future.result()
    }

    # 데이터 처리 및 저장
    processed_data = validate_and_transform_data(raw_data)
    store_to_data_lake(processed_data)

    # 성공 메트릭 전송
    send_collection_metrics(processed_data['validation'])

    return processed_data

def send_collection_metrics(validation_results):
    &quot;&quot;&quot;수집 결과 메트릭 전송&quot;&quot;&quot;
    cloudwatch = boto3.client('cloudwatch')

    for source, results in validation_results.items():
        cloudwatch.put_metric_data(
            Namespace='ExternalDataCollection',
            MetricData=[
                {
                    'MetricName': 'CollectionSuccess',
                    'Value': 1 if results['success'] else 0,
                    'Unit': 'Count',
                    'Dimensions': [
                        {'Name': 'DataSource', 'Value': source}
                    ]
                },
                {
                    'MetricName': 'RecordsCollected',
                    'Value': results.get('record_count', 0),
                    'Unit': 'Count',
                    'Dimensions': [
                        {'Name': 'DataSource', 'Value': source}
                    ]
                }
            ]
        )

# Prefect 배포 설정
if __name__ == &quot;__main__&quot;:
    external_data_collection_flow.serve(
        name=&quot;external-data-collection&quot;,
        cron=&quot;0 * * * *&quot;,  # 매시간 실행
        tags=[&quot;external-data&quot;, &quot;etl&quot;]
    )
</code></pre>

<h2>성과 및 임팩트</h2>
<h3>데이터 수집 성과</h3>
<ul>
<li><strong>데이터 소스 다양성</strong>: 15개 이상 외부 데이터 소스 통합</li>
<li><strong>수집 안정성</strong>: 99.5% 데이터 수집 성공률 달성</li>
<li><strong>실시간성</strong>: 핵심 데이터 1시간 이내 수집 완료</li>
<li><strong>데이터 품질</strong>: 95% 이상 정확한 데이터 검증 통과</li>
</ul>
<h3>비즈니스 임팩트</h3>
<ul>
<li><strong>경쟁사 분석</strong>: 마켓 데이터를 통한 실시간 경쟁사 모니터링 체계 구축</li>
<li><strong>글로벌 인사이트</strong>: 지역별 환율, GeoIP 데이터로 글로벌 서비스 분석 강화</li>
<li><strong>운영 최적화</strong>: 인프라 메트릭 기반 성능 최적화로 서버 비용 15% 절감</li>
<li><strong>의사결정 지원</strong>: 다각도 데이터 분석으로 전략적 의사결정 품질 향상</li>
</ul>
<h3>기술적 성과</h3>
<ul>
<li><strong>확장성</strong>: 플러그인 기반 아키텍처로 새로운 데이터 소스 쉽게 추가</li>
<li><strong>안정성</strong>: 자동 재시도 및 오류 복구 메커니즘으로 99.5% 가용성</li>
<li><strong>효율성</strong>: 병렬 처리와 배치 최적화로 수집 시간 60% 단축</li>
<li><strong>관찰가능성</strong>: 종합적인 모니터링으로 실시간 수집 상태 파악</li>
</ul>
<h2>배운 점과 향후 개선 방향</h2>
<h3>주요 학습 내용</h3>
<ol>
<li><strong>API 제약사항 관리의 중요성</strong></li>
<li>각 플랫폼의 Rate Limiting 정책을 사전에 파악하고 대응 필요</li>
<li>
<p>API 변경 사항에 대한 지속적인 모니터링과 빠른 적응 필요</p>
</li>
<li>
<p><strong>데이터 품질 보장 전략</strong></p>
</li>
<li>소스별 데이터 특성을 고려한 맞춤형 검증 로직 필요</li>
<li>
<p>실시간 데이터 품질 모니터링의 중요성</p>
</li>
<li>
<p><strong>확장 가능한 아키텍처 설계</strong></p>
</li>
<li>새로운 데이터 소스 추가 시 기존 시스템에 미치는 영향 최소화</li>
<li>플러그인 방식의 모듈러 설계의 장점</li>
</ol>
<h3>향후 개선 계획</h3>
<h4>단기 개선 사항 (3-6개월)</h4>
<ul>
<li><strong>스트리밍 강화</strong>: Kafka Connect를 활용한 실시간 스트리밍 수집</li>
<li><strong>AI 기반 이상 탐지</strong>: 수집 데이터 패턴 분석을 통한 자동 이상 탐지</li>
<li><strong>API 버전 관리</strong>: 다양한 API 버전을 지원하는 호환성 레이어 구축</li>
</ul>
<h4>중기 개선 사항 (6-12개월)</h4>
<ul>
<li><strong>지능형 수집</strong>: ML 기반 최적 수집 스케줄링 및 우선순위 조정</li>
<li><strong>데이터 리니지</strong>: Apache Atlas를 통한 완전한 데이터 리니지 추적</li>
<li><strong>자동화 고도화</strong>: 새로운 데이터 소스 자동 발견 및 온보딩</li>
</ul>
<h4>장기 비전 (1-2년)</h4>
<ul>
<li><strong>완전 서버리스</strong>: Step Functions 기반 완전 서버리스 수집 파이프라인</li>
<li><strong>실시간 분석</strong>: 수집과 동시에 실시간 분석 결과 제공</li>
<li><strong>자가 치유</strong>: AI 기반 자동 오류 진단 및 복구 시스템</li>
</ul>
<h3>기술 스택 진화 방향</h3>
<ul>
<li><strong>Apache Airflow</strong>: Prefect에서 Airflow로의 마이그레이션 검토</li>
<li><strong>dbt</strong>: 데이터 변환 로직의 체계적 관리를 위한 dbt 도입</li>
<li><strong>Great Expectations</strong>: 데이터 품질 관리 프레임워크 도입</li>
</ul>
<p>이 프로젝트를 통해 다양한 외부 데이터 소스를 통합하는 복잡한 ETL 시스템의 설계와 운영 노하우를 확보했으며, 각 데이터 소스의 고유 특성을 고려한 맞춤형 접근의 중요성을 깨달았습니다. 특히 API 제약사항과 데이터 품질 관리가 성공의 핵심 요소임을 경험했습니다.</p>
                </div>
            </div>

            <!-- Back to Projects -->
            <div class="text-center mt-12">
                <a href="/#projects" class="inline-flex items-center px-8 py-4 bg-gradient-to-r from-blue-600 to-indigo-600 text-white rounded-full hover:from-blue-700 hover:to-indigo-700 transition-all duration-300 shadow-lg hover:shadow-xl transform hover:-translate-y-1">
                    <i class="fas fa-arrow-left mr-3"></i>
                    프로젝트 목록으로 돌아가기
                </a>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="bg-gray-800 text-white py-12">
        <div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 text-center">
            <p class="text-gray-300">&copy; 2025 SeungHo Choi. All rights reserved.</p>
        </div>
    </footer>

    <!-- Lightbox Modal -->
    <div id="lightbox" class="fixed inset-0 bg-black bg-opacity-80 flex items-center justify-center z-[100] hidden p-4">
        <img id="lightbox-img" src="" alt="Enlarged image" class="max-w-full max-h-full object-contain rounded-lg">
        <button id="lightbox-close" class="absolute top-6 right-6 text-white text-4xl font-bold">&times;</button>
    </div>

    <!-- Prism.js for code highlighting -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const lightbox = document.getElementById('lightbox');
            const lightboxImg = document.getElementById('lightbox-img');
            const lightboxClose = document.getElementById('lightbox-close');

            document.querySelectorAll('.prose img').forEach(img => {
                img.addEventListener('click', () => {
                    lightbox.classList.remove('hidden');
                    lightboxImg.src = img.src;
                });
            });

            const closeLightbox = () => {
                lightbox.classList.add('hidden');
                lightboxImg.src = '';
            };

            lightbox.addEventListener('click', (e) => {
                if (e.target === lightbox) {
                    closeLightbox();
                }
            });

            lightboxClose.addEventListener('click', closeLightbox);

            document.addEventListener('keydown', (e) => {
                if (e.key === 'Escape' && !lightbox.classList.contains('hidden')) {
                    closeLightbox();
                }
            });
        });
    </script>
</body>
</html>